"""
Combine XLS files (one per subject) with lesion metrics computed using SCT's sct_analyze_lesion into a single CSV file
for easier manipulation and visualization.

The script:
 - read XLS files (located under /results) with lesion metrics (computed using sct_analyze_lesion for GT or predicted
 using our 3D nnUNet model)
 - fetch the dorsal and ventral tissue bridges for the mid-sagittal slice
 - save the values in the dataframe and save the dataframe to a CSV file

Note: to read XLS files, you might need to install the following packages:
    pip install openpyxl

Author: Jan Valosek
"""

import os
import sys
import re
import glob
import argparse
import logging

import pandas as pd


# Initialize logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)  # default: logging.DEBUG, logging.INFO
hdlr = logging.StreamHandler(sys.stdout)
logging.root.addHandler(hdlr)

FONT_SIZE = 15


def get_parser():
    """
    parser function
    """

    parser = argparse.ArgumentParser(
        description='Read XLS files (located under /results) with lesion metrics (computed using sct_analyze_lesion),'
                    'construct a dataframe, and save the dataframe to a CSV file',
        prog=os.path.basename(__file__).strip('.py')
    )
    parser.add_argument(
        '-dir',
        required=True,
        type=str,
        help='Abs path to the \'results\' folder with XLS files generated using \'sct_analyze_lesion. '
             'The results folders were generated using the \'01a_compute_tissue_bridges_from_GT.sh\' or '
             '\'01b_compute_tissue_bridges_from_predictions.sh\' script.'
    )
    parser.add_argument(
        '-o',
        required=False,
        default='stats',
        help='Path to the output folder where XLS table will be saved. Default: ./stats'
    )

    return parser


def fetch_subject(filename_path):
    """
    Get subject ID from the input BIDS-compatible filename or file path
    The function works both on absolute file path as well as filename
    :param filename_path: input nifti filename (e.g., sub-001_ses-01_T1w.nii.gz) or file path
    (e.g., /home/user/MRI/bids/derivatives/labels/sub-001/ses-01/anat/sub-001_ses-01_T1w.nii.gz
    :return: subject_session: subject ID (e.g., sub-001)
    """

    subject = re.search('sub-(.*?)[_/]', filename_path)     # [_/] means either underscore or slash
    subjectID = subject.group(0)[:-1] if subject else ""    # [:-1] removes the last underscore or slash
    # REGEX explanation
    # . - match any character (except newline)
    # *? - match the previous element as few times as possible (zero or more times)

    return subjectID


def get_fnames(dir_path, column_name):
    """
    Get list of XLS files with lesion metrics
    :param dir_path: list of paths to XLS files with lesion metrics
    :param column_name: type of the XLS file (e.g., manual or nnunet)
    :return: pandas dataframe with the paths to the XLS files for manual and predicted lesions
    """

    # Get XLS files with lesion metrics
    fname_files = glob.glob(os.path.join(dir_path, '*_lesion*analysis.xls'))
    # remove hidden files starting with '~'
    fname_files = [f for f in fname_files if not os.path.basename(f).startswith('~')]
    # if fname_files is empty, exit
    if len(fname_files) == 0:
        print(f'ERROR: No XLS files found in {dir_path}')

    # Sort the list of file names (to make the list the same when provided the input folders in different order)
    fname_files.sort()

    # Convert fname_files_all into pandas dataframe
    df = pd.DataFrame(fname_files, columns=[column_name])

    # Add a column with participant_id
    df['participant_id'] = df[column_name].apply(lambda x: fetch_subject(x))
    # Make the participant_id column the first column
    df = df[['participant_id', column_name]]
    print(f'Number of participants: {len(df)}')

    return df


def fetch_lesion_metrics(index, row, pred_type, df):
    """
    Fetch lesion metrics from the XLS file with lesion metrics generated by sct_analyze_lesion
    :param index: index of the dataframe
    :param row: row of the dataframe (one row corresponds to one participant)
    :param pred_type: gt or nnunet
    :param df: dataframe with the paths to the XLS files for manual and predicted lesions
    :return: df: updated dataframe with the paths to the XLS files for manual and predicted lesions and lesion metrics
    """

    # Check if the XLS file with lesion metrics for manual lesion exists
    if not os.path.exists(row[pred_type]):
        raise ValueError(f'ERROR: {row[+pred_type]} does not exist.')

    # Read the XLS file with lesion metrics for lesion predicted by our 3D SCIseg nnUNet model
    df_lesion = pd.read_excel(row[pred_type], sheet_name='measures')
    # Get the midsagittal slice number
    midsagittal_slice = str(df_lesion['midsagittal_spinal_cord_slice'].values[0])
    # Get dorsal and ventral tissue bridges for the mid-sagittal slice
    dorsal_tissue_bridge = df_lesion['slice_' + midsagittal_slice + '_dorsal_bridge_width [mm]'].values[0]
    ventral_tissue_bridge = df_lesion['slice_' + midsagittal_slice + '_ventral_bridge_width [mm]'].values[0]

    # One lesion -- # TODO: consider also multiple lesions
    # Save the values in the currently processed df row
    df.at[index, 'ventral_tissue_bridge_'+pred_type] = ventral_tissue_bridge
    df.at[index, 'dorsal_tissue_bridge_'+pred_type] = dorsal_tissue_bridge

    return df


def main():
    # Parse the command line arguments
    parser = get_parser()
    args = parser.parse_args()

    # Output directory
    output_dir = os.path.join(os.getcwd(), args.o)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f'Created {output_dir}')

    # Dump log file there
    fname_log = f'log.txt'
    if os.path.exists(fname_log):
        os.remove(fname_log)
    fh = logging.FileHandler(os.path.join(os.path.abspath(output_dir), fname_log))
    logging.root.addHandler(fh)

    # Check if the input path exists
    if not os.path.exists(args.dir):
        raise ValueError(f'ERROR: {args.dir} does not exist.')

    # For each participant_id, get XLS files with lesion metrics
    df = get_fnames(args.dir, column_name='nnunet')

    # Remove sub-zh111 from the list of participants (it has multiple lesions)
    df = df[df['participant_id'] != 'sub-zh111']

    # Iterate over the rows of the dataframe and read the XLS files
    for index, row in df.iterrows():

        logger.info(f'Processing XLS files for {row["participant_id"]}')

        # Read the XLS file with lesion metrics
        df = fetch_lesion_metrics(index, row, 'nnunet', df)

    # remove the nnunet column containing the paths to the XLS files
    df.drop(columns=['nnunet'], inplace=True)
    # Save the dataframe with lesion metrics to a CSV file
    df.to_csv(os.path.join(output_dir, 'lesion_metrics.csv'), index=False)
    logger.info(f'Saved lesion metrics to {output_dir}/lesion_metrics.csv')


if __name__ == '__main__':
    main()
